{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f6747b8c925d15",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Algorithmic analysis of moderation\n",
    "\n",
    "In this notebook we train a model to predict whether a song will be flagged as violating the openai policies. We use the lyrics of the song as input and the flag as the target. We use a pretrained BERT model and fine-tune it on our data. We use 10-fold cross-validation to evaluate the model.\n",
    "\n",
    "We evaluate the model using precision, recall, and F1 score. We also create a random baseline to compare the model to. The random baseline predicts flagged with probability equal to the proportion of flagged songs in the training set.\n",
    "\n",
    "We are following the [Hugging Face tutorial](https://huggingface.co/docs/transformers/training) for training a model on a custom dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cdc68f82b7d4d97",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T12:36:40.312340700Z",
     "start_time": "2024-01-29T12:36:40.300994400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T12:36:49.558864200Z",
     "start_time": "2024-01-29T12:36:40.317692700Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import json\n",
    "import zipfile\n",
    "from datetime import datetime\n",
    "\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import KFold\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from utils.config import PROJECT_ROOT, DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a266d3251ae42a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T12:36:49.572553500Z",
     "start_time": "2024-01-29T12:36:49.553914900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "EXP_DIR = PROJECT_ROOT / \"experiments\"\n",
    "EXP_DATA_DIR = DATA_DIR / \"experiments\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f03ff017385cdd3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T12:36:49.612334400Z",
     "start_time": "2024-01-29T12:36:49.569131800Z"
    }
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = \"bert-base-multilingual-cased\"\n",
    "TRAIN_ARGS = TrainingArguments(\n",
    "    output_dir=EXP_DIR / \"results\",\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_ratio=0.1,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a16aeda90425658",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T12:36:54.017224200Z",
     "start_time": "2024-01-29T12:36:49.615528200Z"
    }
   },
   "outputs": [],
   "source": [
    "f1_score = evaluate.load(\"f1\")\n",
    "precision = evaluate.load(\"precision\")\n",
    "recall = evaluate.load(\"recall\")\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"\n",
    "    Compute metric for a given evaluation prediction.\n",
    "    \"\"\"\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = predictions.argmax(axis=1)\n",
    "\n",
    "    results = {}\n",
    "    for metric in (f1_score, precision, recall):\n",
    "        results.update(metric.compute(predictions=predictions, references=labels))\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc6261bb9872a6ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T12:36:54.059263200Z",
     "start_time": "2024-01-29T12:36:54.025685600Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_gen(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Get a generator that yields the lyrics and labels for each song.\n",
    "    \"\"\"\n",
    "\n",
    "    def gen():\n",
    "        with zipfile.ZipFile(DATA_DIR / \"lyrics.zip\") as zf:\n",
    "            for i, row in df.iterrows():\n",
    "                lyrics = zf.read(f\"{row['song_id']}.txt\").decode(\"utf-8\")\n",
    "                yield {\"text\": lyrics, \"labels\": int(row[\"flagged\"])}\n",
    "\n",
    "    return gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c82e67215c779c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T12:36:54.061410900Z",
     "start_time": "2024-01-29T12:36:54.053770700Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_ds(df: pd.DataFrame, tokenizer):\n",
    "    \"\"\"\n",
    "    Get a dataset from a dataframe.\n",
    "    \"\"\"\n",
    "\n",
    "    def tokenize(batch):\n",
    "        return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "    ds = Dataset.from_generator(get_gen(df))\n",
    "    ds = ds.map(tokenize).remove_columns([\"text\"])\n",
    "    ds.set_format(\"torch\")\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57fe88dd5199e971",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T12:36:54.087087600Z",
     "start_time": "2024-01-29T12:36:54.064650800Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_model_and_tokenizer():\n",
    "    \"\"\"\n",
    "    Load the model and tokenizer.\n",
    "    \"\"\"\n",
    "    return (\n",
    "        AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2),\n",
    "        AutoTokenizer.from_pretrained(MODEL_NAME),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c71cad5f4bf88b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T12:36:54.107501700Z",
     "start_time": "2024-01-29T12:36:54.080546Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_training(train_df: pd.DataFrame, valid_df: pd.DataFrame) -> dict:\n",
    "    \"\"\"\n",
    "    Run the training and evaluation for one fold.\n",
    "    \"\"\"\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    model, tokenizer = load_model_and_tokenizer()\n",
    "    train_dataset = get_ds(train_df, tokenizer)\n",
    "    valid_dataset = get_ds(valid_df, tokenizer)\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=TRAIN_ARGS,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=valid_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    trainer.train()\n",
    "    trainer.save_model(EXP_DIR / \"models\" / datetime.now().isoformat())\n",
    "\n",
    "    return trainer.evaluate(valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e4587aeba1ef910",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T12:41:22.208989700Z",
     "start_time": "2024-01-29T12:41:22.193888100Z"
    }
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Run the training and evaluation for all folds.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(DATA_DIR / \"csv\" / \"moderation.csv\")\n",
    "    assert not df.song_id.duplicated().any(), \"Duplicate song IDs found\"\n",
    "\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "    for i, (train_index, valid_index) in enumerate(kf.split(df), 1):\n",
    "        train_df = df.iloc[train_index]\n",
    "        valid_df = df.iloc[valid_index]\n",
    "\n",
    "        # bert training\n",
    "        results = run_training(train_df, valid_df)\n",
    "        results[\"model\"] = MODEL_NAME\n",
    "\n",
    "        with open(EXP_DATA_DIR / \"exp_PD_001_AlgorithmicAnalysis.jsonl\", \"a\") as f:\n",
    "            f.write(json.dumps(results) + \"\\n\")\n",
    "\n",
    "        # random baseline\n",
    "        p_flagged = train_df.flagged.mean()\n",
    "        predictions = np.random.binomial(1, p_flagged, size=len(valid_df))\n",
    "        results_baseline = {}\n",
    "        for metric_fct in (f1_score, precision, recall):\n",
    "            metric = metric_fct.compute(\n",
    "                predictions=predictions, references=valid_df.flagged.values\n",
    "            )\n",
    "            results_baseline.update({f\"eval_{key}\": val for key, val in metric.items()})\n",
    "        results_baseline[\"model\"] = \"random_baseline\"\n",
    "\n",
    "        with open(EXP_DATA_DIR / \"exp_PD_001_AlgorithmicAnalysis.jsonl\", \"a\") as f:\n",
    "            f.write(json.dumps(results_baseline) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4675c80ec3849ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T12:41:23.852861800Z",
     "start_time": "2024-01-29T12:41:23.005787Z"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# run training and create baseline. Save results to jsonl file.\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "model                bert-base-multilingual-cased  random_baseline\neval_f1        mean                      0.662586         0.289544\n               std                       0.016042         0.023108\neval_precision mean                      0.664560         0.290230\n               std                       0.027976         0.024650\neval_recall    mean                      0.663373         0.289267\n               std                       0.041551         0.024524",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>bert-base-multilingual-cased</th>\n      <th>random_baseline</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">eval_f1</th>\n      <th>mean</th>\n      <td>0.662586</td>\n      <td>0.289544</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.016042</td>\n      <td>0.023108</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">eval_precision</th>\n      <th>mean</th>\n      <td>0.664560</td>\n      <td>0.290230</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.027976</td>\n      <td>0.024650</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">eval_recall</th>\n      <th>mean</th>\n      <td>0.663373</td>\n      <td>0.289267</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.041551</td>\n      <td>0.024524</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's look at the results\n",
    "results_df = pd.read_json(\n",
    "    EXP_DATA_DIR / \"exp_PD_001_AlgorithmicAnalysis.jsonl\", lines=True\n",
    ")\n",
    "results_df = results_df[[\"model\", \"eval_f1\", \"eval_precision\", \"eval_recall\"]]\n",
    "results_df = results_df.groupby(\"model\").agg([\"mean\", \"std\"]).transpose()\n",
    "results_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T13:29:35.141085800Z",
     "start_time": "2024-01-29T13:29:35.110800600Z"
    }
   },
   "id": "49eac2b9ae64e2ee",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "results_df.reset_index().to_csv(EXP_DATA_DIR / \"exp_PD_001_AlgorithmicAnalysis.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T13:29:43.571873200Z",
     "start_time": "2024-01-29T13:29:43.555720800Z"
    }
   },
   "id": "22af0a601921f244",
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1f2d55b4fe04ace3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
